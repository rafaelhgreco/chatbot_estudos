import streamlit as st
import requests
import json
import os
from dotenv import load_dotenv

# Importar mÃ³dulos do projeto
from modules.workflow_manager import WorkflowManager, EstadoConversa
from modules import prompt_templates as prompts
from utils.validators import validar_tema, validar_metodologia

# Load environment variables from .env file
load_dotenv()


# ============================================================================
# FUNÃ‡Ã•ES AUXILIARES
# ============================================================================

def chamar_gemini(api_key: str, prompt_usuario: str, historico: list) -> str:
    """
    Chama a API do Gemini e retorna a resposta.
    
    Args:
        api_key: Chave da API do Google
        prompt_usuario: Prompt/mensagem do usuÃ¡rio
        historico: HistÃ³rico de mensagens anteriores
    
    Returns:
        Resposta do modelo ou mensagem de erro
    """
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key={api_key}"
        headers = {"Content-Type": "application/json"}
        
        # Adiciona prompt de sistema e contexto
        mensagens = [
            {"role": "user", "parts": [{"text": prompts.SYSTEM_PROMPT}]},
            {"role": "model", "parts": [{"text": "Entendido. Estou pronto para ajudar a criar cronogramas de estudo personalizados."}]}
        ]
        
        # Adiciona histÃ³rico
        for msg in historico:
            role = "model" if msg["role"] == "assistant" else "user"
            mensagens.append({"role": role, "parts": [{"text": msg["content"]}]})
        
        # Adiciona mensagem atual
        mensagens.append({"role": "user", "parts": [{"text": prompt_usuario}]})
        
        data = {"contents": mensagens}
        
        response = requests.post(url, headers=headers, json=data, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        if "candidates" in result and result["candidates"]:
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            return "âš ï¸ NÃ£o foi possÃ­vel obter uma resposta. Tente novamente."
    
    except requests.exceptions.Timeout:
        return "âš ï¸ A requisiÃ§Ã£o demorou muito. Tente um tema mais especÃ­fico ou um prazo menor."
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 429:
            return "âš ï¸ Limite de uso da API atingido. Aguarde alguns minutos."
        elif e.response.status_code == 404:
            return "âš ï¸ Modelo nÃ£o encontrado."
        else:
            return f"âš ï¸ Erro HTTP {e.response.status_code}"
    except Exception as e:
        return f"âš ï¸ Erro: {str(e)}"


def processar_mensagem_usuario(mensagem: str, api_key: str):
    """Processa mensagem do usuÃ¡rio com base no estado atual do workflow."""
    
    workflow = st.session_state.workflow
    estado_atual = workflow.get_estado()
    
    with st.chat_message("assistant"):
        # Estado INICIAL -> Coletar tema
        if estado_atual == EstadoConversa.INICIAL:
            workflow.processar_tema(mensagem)
            
            prompt = prompts.PROMPT_CONFIRMAR_TEMA.format(tema=mensagem)
            resposta = chamar_gemini(api_key, prompt, st.session_state.messages[-5:])
            
            st.markdown(resposta)
            st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        # Estado COLETANDO_TEMA -> mesma lÃ³gica
        elif estado_atual == EstadoConversa.COLETANDO_TEMA:
            workflow.processar_tema(mensagem)
            
            prompt = prompts.PROMPT_CONFIRMAR_TEMA.format(tema=mensagem)
            resposta = chamar_gemini(api_key, prompt, st.session_state.messages[-5:])
            
            st.markdown(resposta)
            st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        # Estado APRESENTANDO_METODOLOGIAS -> Processar escolha de metodologia
        elif estado_atual == EstadoConversa.APRESENTANDO_METODOLOGIAS:
            workflow.processar_metodologia(mensagem)
            
            dados = workflow.get_dados()
            prompt = prompts.PROMPT_COLETAR_PARAMETROS.format(
                tema=dados.tema,
                metodologia=dados.metodologia
            )
            resposta = chamar_gemini(api_key, prompt, st.session_state.messages[-5:])
            
            st.markdown(resposta)
            st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        # Estado COLETANDO_PARAMETROS -> Processar parÃ¢metros
        elif estado_atual == EstadoConversa.COLETANDO_PARAMETROS:
            novo_estado, tipo_prompt, completo = workflow.processar_parametros(mensagem)
            
            if completo:
                # Tem todos os parÃ¢metros, gerar cronograma
                dados = workflow.get_dados()
                
                st.info("â³ Gerando seu cronograma personalizado... Isso pode levar alguns segundos.")
                
                prompt_cronograma = prompts.construir_prompt_cronograma(
                    tema=dados.tema,
                    metodologia=dados.metodologia,
                    tempo=dados.tempo_disponivel,
                    prazo=dados.prazo,
                    nivel=dados.nivel
                )
                
                cronograma = chamar_gemini(api_key, prompt_cronograma, [])
                
                workflow.cronograma_gerado(cronograma)
                
                st.markdown(cronograma)
                st.session_state.messages.append({"role": "assistant", "content": cronograma})
                
                # Perguntar feedback
                msg_feedback = "\n\n---\n\nâœ… O que achou do cronograma? EstÃ¡ de acordo com suas expectativas?\n\nVocÃª pode aprovar (ğŸ‘), solicitar ajustes especÃ­ficos, ou pedir para refazer."
                st.markdown(msg_feedback)
                st.session_state.messages.append({"role": "assistant", "content": msg_feedback})
            else:
                # Ainda falta informaÃ§Ãµes
                faltando = workflow.get_faltando_parametros()
                dados = workflow.get_dados()
                
                prompt_reforco = f"O usuÃ¡rio forneceu: '{mensagem}'\n\nAinda faltam: {', '.join(faltando)}\n\nTema: {dados.tema}\nMetodologia: {dados.metodologia}\n\nPergunte APENAS as informaÃ§Ãµes que faltam de forma amigÃ¡vel."
                
                resposta = chamar_gemini(api_key, prompt_reforco, st.session_state.messages[-3:])
                
                st.markdown(resposta)
                st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        # Estado APRESENTANDO_CRONOGRAMA ou COLETANDO_FEEDBACK -> Processar feedback
        elif estado_atual in [EstadoConversa.APRESENTANDO_CRONOGRAMA, EstadoConversa.COLETANDO_FEEDBACK]:
            novo_estado, tipo_acao = workflow.processar_feedback(mensagem)
            
            if tipo_acao == "feedback_positivo":
                resposta = "ğŸ‰ Ã“timo! Seu cronograma estÃ¡ aprovado!\n\nğŸ“¥ **PrÃ³ximos passos:**\n- Salve este cronograma\n- Comece pelos primeiros tÃ³picos\n- Mantenha consistÃªncia nos estudos\n\nQuer criar um novo cronograma de estudos?"
                st.markdown(resposta)
                st.session_state.messages.append({"role": "assistant", "content": resposta})
            
            elif tipo_acao == "feedback_negativo_generico":
                resposta = "Entendo que nÃ£o ficou como esperava. Pode me dizer especificamente o que gostaria de mudar?\n\nPor exemplo:\n- Prazo muito longo/curto?\n- ConteÃºdo muito bÃ¡sico/avanÃ§ado?\n- Faltam exercÃ­cios prÃ¡ticos?\n- Outro aspecto?"
                st.markdown(resposta)
                st.session_state.messages.append({"role": "assistant", "content": resposta})
            
            elif tipo_acao == "refinar_cronograma":
                st.info("â³ Refinando o cronograma com base no seu feedback...")
                
                dados = workflow.get_dados()
                prompt_refinamento = prompts.PROMPT_PROCESSAR_FEEDBACK.format(
                    cronograma_anterior=dados.cronograma_atual,
                    feedback=mensagem
                )
                
                novo_cronograma = chamar_gemini(api_key, prompt_refinamento, [])
                
                workflow.cronograma_refinado(novo_cronograma)
                
                st.markdown("ğŸ”„ **Cronograma Atualizado:**\n\n" + novo_cronograma)
                st.session_state.messages.append({"role": "assistant", "content": novo_cronograma})
                
                msg_feedback = "\n\n---\n\nO que achou agora? Posso fazer mais algum ajuste?"
                st.markdown(msg_feedback)
                st.session_state.messages.append({"role": "assistant", "content": msg_feedback})
            
            else:  # pedir_esclarecimento
                resposta = "NÃ£o entendi bem o que vocÃª gostaria de mudar. Pode ser mais especÃ­fico?\n\nPor exemplo: 'Reduzir para 6 semanas' ou 'Adicionar mais projetos prÃ¡ticos'"
                st.markdown(resposta)
                st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        # Estado APROVADO -> Oferecer novo cronograma
        elif estado_atual == EstadoConversa.APROVADO:
            if any(palavra in mensagem.lower() for palavra in ['sim', 'quero', 'novo', 'outro']):
                workflow.resetar()
                st.session_state.messages = []
                st.rerun()
            else:
                resposta = "Obrigado por usar o Chatbot de Estudos! Bons estudos! ğŸ“šâœ¨"
                st.markdown(resposta)
                st.session_state.messages.append({"role": "assistant", "content": resposta})
        
        st.rerun()


# ============================================================================
# INTERFACE PRINCIPAL
# ============================================================================

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Chatbot de Estudos Personalizados",
    page_icon="ğŸ“š",
    layout="wide"
)

# Show title and description.
st.title("ğŸ“š Chatbot de Estudos Personalizados")
st.write(
    "Crie cronogramas de estudo personalizados com metodologias comprovadas de aprendizagem!"
)

# Get API key from environment variable or user input
# Try Streamlit secrets first (for Streamlit Cloud), then environment variable
try:
    google_api_key = st.secrets.get("GEMINI_API_KEY", "")
except:
    google_api_key = os.environ.get("GEMINI_API_KEY", "")

# If no API key in environment, ask user for input
if not google_api_key:
    google_api_key = st.text_input("Google API Key", type="password")
    if not google_api_key:
        st.info("Por favor, adicione sua chave API do Google para continuar (ou configure no arquivo .env)", icon="ğŸ—ï¸")
else:
    # Inicializar WorkflowManager e session state
    if "workflow" not in st.session_state:
        st.session_state.workflow = WorkflowManager()
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Sidebar com informaÃ§Ãµes de progresso
    with st.sidebar:
        st.header("ğŸ“Š Progresso")
        progresso = st.session_state.workflow.get_progresso()
        st.progress(progresso["percentual"] / 100)
        st.write(f"**{progresso['descricao']}**")
        st.write(f"Etapa {progresso['etapa_atual']} de {progresso['total_etapas']}")
        
        st.divider()
        
        # Mostrar informaÃ§Ãµes coletadas
        dados = st.session_state.workflow.get_dados()
        if dados.tema:
            st.write(f"ğŸ“š **Tema:** {dados.tema}")
        if dados.metodologia:
            st.write(f"ğŸ¯ **Metodologia:** {dados.metodologia}")
        if dados.tempo_disponivel:
            st.write(f"â° **Tempo:** {dados.tempo_disponivel}")
        if dados.prazo:
            st.write(f"ğŸ“… **Prazo:** {dados.prazo}")
        if dados.nivel:
            st.write(f"ğŸ“Š **NÃ­vel:** {dados.nivel}")
        
        st.divider()
        
        if st.button("ğŸ”„ Reiniciar Conversa"):
            st.session_state.workflow.resetar()
            st.session_state.messages = []
            st.rerun()
    
    # Se primeira vez, enviar mensagem de boas-vindas
    if len(st.session_state.messages) == 0:
        mensagem_boas_vindas = chamar_gemini(
            google_api_key, 
            prompts.PROMPT_BOAS_VINDAS,
            []
        )
        st.session_state.messages.append({"role": "assistant", "content": mensagem_boas_vindas})

    # Display the existing chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input("Digite sua mensagem..."):
        # Store and display user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Process message based on current state
        processar_mensagem_usuario(prompt, google_api_key)


